version: '3.6'

services:
  api:
    container_name: local-ai
    image: quay.io/go-skynet/local-ai:v1.20.0-cublas-cuda12-ffmpeg #master-cublas-cuda12 #v1.20.0-cublas-cuda12-ffmpeg
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    ports:
      - 8080:8080
    env_file:
      - .env
    environment:
        - MODELS_PATH=/models
        - 'PRELOAD_MODELS=[{"url": "https://raw.githubusercontent.com/go-skynet/model-gallery/main/vicuna.yaml","name":"vicuna", "overrides": { "f16":true, "gpu_layers": 100, "mmap": true, "batch": 700 } } ]'        
        - BUILD_TYPE=cublas
        - NVIDIA_VISIBLE_DEVICES=all
        - NVIDIA_DRIVER_CAPABILITIES=all
    volumes:
        - ./models:/models:cached
        - ./pictures/:/tmp/
    command: ["/usr/bin/local-ai"]

  flowise:
    container_name: flowise-ai
    image: flowiseai/flowise:latest
    restart: always
    ports:
        - 3000:3000
    environment:
      - EXECUTION_MODE=child
      - DEBUG=false
      - LOG_PATH=./logs
    volumes:
        - ~/.flowise:/root/.flowise
        - ./logs/:/logs/
    command: /bin/sh -c "sleep 3; flowise start"

  # langflow:
  #   container_name: langflow-ai
  #   restart: always
  #   image: garystafford/langflow:0.2.0
  #   security_opt:
  #     - seccomp:unconfined
  #   ports:
  #     - "3000:7860"
  #   command: langflow --host 0.0.0.0
version: '3.6'

services:
  api:
    container_name: localai
    image: quay.io/go-skynet/local-ai:v1.23.0-cublas-cuda12 #master-cublas-cuda12 #v1.20.0-cublas-cuda12-ffmpeg
    restart: always
    # build:
    #   context: .
    #   dockerfile: Dockerfile
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    ports:
      - 8080:8080
    env_file:
      - .env
    environment:
        - MODELS_PATH=/models
        - BUILD_TYPE=cublas
        - NVIDIA_VISIBLE_DEVICES=all
        - NVIDIA_DRIVER_CAPABILITIES=all
        - DEBUG=true
        - 'PRELOAD_GALLERIES=[{"name":"model-gallery", "url":"github:go-skynet/model-gallery/vicuna.yaml"}, {"url": "github:ci-robbot/localai-huggingface-zoo/index.yaml","name":"huggingface"}]'
    volumes:
        - ./models:/models:cached
        - ./pictures/:/tmp/
    command: ["/usr/bin/local-ai --gpus all"]
    networks:
      - web-secure

  redis:
    image: redis:6.2.6
    container_name: localai.redis
    command: "redis-server --requirepass false"
    volumes:
      - ./redis:/data
    networks:
      - web-secure
    restart: unless-stopped
    environment:
      - REDIS_REPLICATION_MODE=master
    ports:
      - 6379:6379

  flowise:
    container_name: localai.flowise
    image: flowiseai/flowise:latest
    restart: always
    ports:
        - 3000:3000
    environment:
      - EXECUTION_MODE=main
      - DEBUG=false
      - LOG_PATH=./logs
    volumes:
        - ~/.flowise:/root/.flowise
        - ./logs/:/logs/
    command: /bin/sh -c "sleep 3; flowise start"
    networks:
      - web-secure

networks:
  web-secure:
    external: true
